# EntropyWatcher Utility Scripts

Detaillierte Dokumentation fÃ¼r Status-Monitoring, Safety-Gate und Forecasting-Tools. Diese Scripts bieten erweiterte FunktionalitÃ¤t fÃ¼r Pipeline-Ãœberwachung und -Planung.

---

## ğŸ“‹ Ãœbersicht

| Script | Zweck | KomplexitÃ¤t | Output |
|--------|-------|-------------|--------|
| `safety_gate.sh` | Pre-Backup Security Check | Mittel | Exitcode (0/1/2) |
| `scripts/ew_status.sh` | Service-Health-Dashboard | Hoch | Terminal/HTML/Mail |
| `scripts/ew_forecast_next_run.sh` | Timer-Status-Ãœbersicht | Niedrig | ASCII/Box-Tabelle |
| `scripts/forecast_safety_gate.sh` | Safety-Gate Forecasting | Hoch | Zeitlinien-Tabelle |
| `scripts/ew_backup_slot_check.sh` | Backup-Slot-Check | Mittel | Service-Status-Tabelle |

---

## ğŸ›¡ï¸ safety_gate.sh

**Zweck:** Zentraler Pre-Backup-Check fÃ¼r RTB-Wrapper und pCloud-Tools. PrÃ¼ft Honeyfile-IntegritÃ¤t und EntropyWatcher-Status.

### Funktionsweise

1. **Pre-Flight:** Honeyfile-Check (Fail-Fast bei System-Kompromittierung)
2. **EntropyWatcher-Status:** PrÃ¼ft `nas` + `nas-av` Services
3. **Exitcode:** 0=GREEN (safe), 1=YELLOW (warning), 2=RED (blocked)

### Usage

```bash
# Standard-Modus (blockiert nur bei RED)
./safety_gate.sh

# Strict-Modus (blockiert auch bei YELLOW)
./safety_gate.sh --strict
```

### Exitcodes

| Code | Status | Bedeutung | Backup erlaubt? |
|------|--------|-----------|-----------------|
| **0** | GREEN | Alle Checks OK | âœ… Ja |
| **1** | YELLOW | Warnungen (z.B. veraltete Scans) | âœ… Ja (âŒ Nein im --strict) |
| **2** | RED | Kritisch (Honeyfile-Alarm, AV-Funde) | âŒ Nein |

### Environment Variables

```bash
# Honeyfile-Check deaktivieren (fÃ¼r Testing)
CHECK_HONEYFILES=0 ./safety_gate.sh

# Custom Pfade
HONEYFILE_FLAG=/custom/path/alert ./safety_gate.sh
HONEYFILE_AUDIT_KEY=custom_key ./safety_gate.sh

# EntropyWatcher-Pfade Ã¼berschreiben
ENTROPYWATCHER_PY=/opt/venv/bin/python \
ENTROPYWATCHER_SCRIPT=/opt/ew/entropywatcher.py \
ENTROPYWATCHER_COMMON_ENV=/opt/config/common.env \
./safety_gate.sh
```

### Architektur

**Checked Services:**
- `nas` - NAS-Dateien Entropy-Scan
- `nas-av` - NAS-AV-Hot-Scan (Downloads, Incoming)

**Nicht geprÃ¼ft:**
- `os`, `os-av` - OS-Scans sind nicht backup-relevant (Cloud-Backups betreffen nur NAS)
- `*-weekly` - WÃ¶chentliche Scans sind optional

**Honeyfile-Check (Tier 1 + Live):**
1. Flag-File `/var/lib/honeyfile_alert` prÃ¼fen
2. Live Audit-Log abfragen (ausearch -k honeyfile_access)
3. Bei **irgendeinem** Treffer â†’ EXIT 2 (RED)

**EntropyWatcher-Status:**
```bash
# Intern ausgefÃ¼hrt:
python entropywatcher.py --env common.env --env nas.env status --json-out /dev/null
```

### Integration

**RTB-Wrapper:**
```bash
# In rtb_wrapper.sh:
if ! /opt/apps/entropywatcher/main/safety_gate.sh; then
  echo "BACKUP BLOCKIERT - Safety-Gate RED/YELLOW"
  exit 1
fi
```

**pCloud-Tools:**
```bash
# In pcloud_sync.sh:
SAFETY_GATE_EXIT=0
/opt/apps/entropywatcher/main/safety_gate.sh || SAFETY_GATE_EXIT=$?

if [[ $SAFETY_GATE_EXIT -eq 2 ]]; then
  echo "CRITICAL: Safety-Gate RED - Upload blockiert"
  exit 2
fi
```

### Troubleshooting

**Problem:** "SYSTEM KOMPROMITTIERT - BACKUP BLOCKIERT"

**Ursache:** Honeyfile wurde zugegriffen.

**LÃ¶sung:**
```bash
# 1. Audit-Log prÃ¼fen
sudo ausearch -k honeyfile_access --start recent

# 2. Alert-Flag entfernen (nach PrÃ¼fung!)
sudo rm /var/lib/honeyfile_alert

# 3. Re-Test
./safety_gate.sh
```

**Problem:** "Service-ENV nicht gefunden"

**Ursache:** `/opt/apps/entropywatcher/config/nas.env` fehlt.

**LÃ¶sung:**
```bash
# Konfiguration prÃ¼fen
ls -la /opt/apps/entropywatcher/config/
```

---

## ğŸ“Š ew_status.sh

**Zweck:** Umfassendes Dashboard fÃ¼r alle EntropyWatcher-Services. Zeigt DB-Status, Service-Gesundheit, AV-Funde, flagged files.

### Usage

```bash
# Terminal-Dashboard (interaktiv)
./ew_status.sh /opt/apps/entropywatcher/config dashboard

# HTML-Report generieren & per Mail versenden
./ew_status.sh /opt/apps/entropywatcher/config mail
```

### Modes

#### 1. Dashboard-Modus (Terminal)

**Output:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Service        â•‘ Status     â•‘ Last Scan         â•‘ Age Min â•‘ Window Min â•‘ Buffer Ã¼brig %â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ nas            â•‘ GREEN      â•‘ 2025-12-14 10:20  â•‘      15 â•‘         75 â•‘         80.0% â•‘
â•‘ nas-av         â•‘ YELLOW     â•‘ 2025-12-13 09:00  â•‘    1480 â•‘       1560 â•‘          5.1% â•‘
â•‘ os             â•‘ GREEN      â•‘ 2025-12-14 03:40  â•‘     400 â•‘       1560 â•‘         74.4% â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Spalten-ErklÃ¤rung:**
- **Service:** SOURCE_LABEL aus .env
- **Status:** GREEN (OK), YELLOW (Warnung), RED (Alarm)
- **Last Scan:** Letzter `scanned_at` aus DB
- **Age Min:** Alter des letzten Scans in Minuten
- **Window Min:** `HEALTH_WINDOW_MIN` fÃ¼r diesen Service
- **Buffer Ã¼brig %:** Prozent des Zeitfensters noch verfÃ¼gbar

#### 2. Mail-Modus (HTML)

**Generiert HTML-Report:**
```html
<!DOCTYPE html>
<html>
<head>
  <style>
    /* Dark Theme, Courier Font */
    body { background: #1e1e1e; color: #e0e0e0; }
    .GREEN { color: #28a745; }
    .YELLOW { color: #ffc107; }
    .RED { color: #dc3545; }
  </style>
</head>
<body>
  <h1>EntropyWatcher Status - 2025-12-14 11:00</h1>
  <table>
    <!-- Service-Status-Tabelle -->
  </table>
  
  <h2>AV-Funde (letzte 7 Tage)</h2>
  <pre><!-- ClamAV-Funde-Liste --></pre>
  
  <h2>Flagged Files (letzte 7 Tage)</h2>
  <pre><!-- Entropie-Flags-Liste --></pre>
</body>
</html>
```

**Mail-Versand:**
- Nutzt Python `smtplib` + SMTP-Config aus `common.env`
- EnthÃ¤lt vollstÃ¤ndige Tabellen + Attachment (optional)

### Architektur

**Service-Discovery:**
```bash
# Automatisch alle *.env in CONFIG_DIR scannen
for env_file in /opt/apps/entropywatcher/config/*.env; do
  SOURCE_LABEL=$(grep -E '^SOURCE_LABEL=' "$env_file")
  HEALTH_WINDOW_MIN=$(grep -E '^HEALTH_WINDOW_MIN=' "$env_file")
  SERVICES["$SOURCE_LABEL"]="$env_file"
  WINDOWS["$SOURCE_LABEL"]="$HEALTH_WINDOW_MIN"
done
```

**Health-Status-Berechnung:**
```bash
# Status-Logik (pro Service):
last_scan_epoch=$(mysql_query "SELECT MAX(scanned_at) FROM files WHERE source='$SERVICE'")
age_min=$((current_epoch - last_scan_epoch) / 60)
buffer_pct=$(( (window_min - age_min) * 100 / window_min ))

if [[ $age_min -le $window_min ]]; then
  status="GREEN"
elif [[ $age_min -le $((window_min + 60)) ]]; then
  status="YELLOW"  # Grace Period (60 Min)
else
  status="RED"
fi
```

**DB-Queries:**
- `MAX(scanned_at)` - Letzter Scan-Zeitstempel
- `COUNT(*) WHERE flagged_at IS NOT NULL` - Flagged files
- ClamAV-Findings-Tabelle (falls vorhanden)

### Troubleshooting

**Problem:** "ERROR: common.env nicht gefunden"

**LÃ¶sung:**
```bash
# Korrekten Pfad angeben
./ew_status.sh /correct/path/to/config dashboard
```

**Problem:** "Keine Services gefunden"

**Ursache:** Keine `.env`-Dateien mit `SOURCE_LABEL` in config/.

**LÃ¶sung:**
```bash
# PrÃ¼fen
grep -r "SOURCE_LABEL" /opt/apps/entropywatcher/config/
```

**Problem:** "Status immer YELLOW trotz aktuellem Scan"

**Ursache:** `HEALTH_WINDOW_MIN` zu eng oder System-Clock-Drift.

**LÃ¶sung:**
```bash
# Window erweitern (in service.env):
HEALTH_WINDOW_MIN=120  # statt 75

# Clock-Drift prÃ¼fen:
timedatectl status
```

---

## â±ï¸ ew_forecast_next_run.sh

**Zweck:** Zeigt Timer-Status aller EntropyWatcher-Services an. Kompakte Ãœbersicht Ã¼ber LastRun, NextRun, Enabled/Active.

### Usage

```bash
# ASCII-Stil (Standard)
./ew_forecast_next_run.sh

# Box-Stil (Unicode-Boxen, schÃ¶ner)
STYLE=box ./ew_forecast_next_run.sh
```

### Output

**ASCII-Stil:**
```
EntropyWatcher / Backup-Pipeline Timer-Status

Unit                                | Enabled | Active  | LastRun                                      | NextRun
------------------------------------+--------+---------+----------------------------------------------+--------------------------------------------
entropywatcher-nas.timer            | enabled| active  | Sun 2025-12-14 10:20:22 CET (15m ago)        | Sun 2025-12-14 11:20:00 CET (45m left)
entropywatcher-os.timer             | enabled| active  | Sun 2025-12-14 03:40:00 CET (7h ago)         | Mon 2025-12-15 03:40:00 CET (16h left)
backup-pipeline.timer               | enabled| active  | Sun 2025-12-14 05:00:00 CET (6h ago)         | Mon 2025-12-15 05:00:00 CET (17h left)
```

**Box-Stil:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Unit                                â”‚ Enabled â”‚ Active  â”‚ LastRun                                    â”‚ NextRun                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ entropywatcher-nas.timer            â”‚ enabled â”‚ active  â”‚ Sun 2025-12-14 10:20:22 CET (15m ago)      â”‚ Sun 2025-12-14 11:20:00 CET (45m left)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architektur

**Datenquelle:**
```bash
# systemctl list-timers parsen
systemctl list-timers entropywatcher-nas.timer

# Output-Format (Zeile 2):
# Sun 2025-12-14 11:20:00 CET 45min left  Sun 2025-12-14 10:20:22 CET 15min ago  entropywatcher-nas.timer
```

**Relative Zeit kÃ¼rzen:**
```bash
# "15 minutes ago" â†’ "15m ago"
# "2 hours left" â†’ "2h left"
# "3 days ago" â†’ "3d ago"
shorten_rel() {
  echo "$1" | sed -E \
    -e 's/([0-9]+)[[:space:]]*days?/\1d/g' \
    -e 's/([0-9]+)[[:space:]]*hours?/\1h/g' \
    -e 's/([0-9]+)[[:space:]]*mins?/\1m/g'
}
```

### Use Cases

**Quick-Check:**
```bash
# Vor Backup-Pipeline-Start
./ew_forecast_next_run.sh | grep -E "(active|enabled)"
```

**Overlap-Detection:**
```bash
# Timer zu eng getaktet?
STYLE=box ./ew_forecast_next_run.sh | grep "left"
```

**Systemd-Integration:**
```bash
# In Monitoring-Cronjob
if ! ./ew_forecast_next_run.sh | grep -q "entropywatcher-nas.timer"; then
  echo "ERROR: NAS-Timer nicht gefunden"
  exit 1
fi
```

---

## ğŸ”® forecast_safety_gate.sh

**Zweck:** Forecast-Tool fÃ¼r zukÃ¼nftige Safety-Gate-ZustÃ¤nde. Simuliert ob Backups zu geplanten Zeitpunkten erlaubt wÃ¤ren.

### Usage

```bash
# Forecast fÃ¼r morgen
./forecast_safety_gate.sh 1

# Forecast fÃ¼r nÃ¤chste Woche
./forecast_safety_gate.sh 7

# Forecast fÃ¼r heute (default: 0)
./forecast_safety_gate.sh
```

### Output

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SAFETY-GATE FORECAST: 2025-12-15 (Target: Mo 05:00)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Service       Schedule         LastRun (@ Target)                Age (min)  Window (min)  Status
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
nas           1h (:20)         Mo 2025-12-15 04:20:00           40         75            GREEN
nas-av        taegl (09:00)    So 2025-12-14 09:00:00           1200       1560          GREEN
os            1d (03:40)       Mo 2025-12-15 03:40:00           80         1560          GREEN

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FORECAST RESULT @ Mo 05:00: GREEN (alle Services im Window)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Architektur

**Forecast-Algorithmus:**

1. **Ziel-Zeitpunkt berechnen:**
   ```bash
   target_epoch=$(date -d "+${OFFSET_DAYS} days 05:00:00" +%s)
   ```

2. **Pro Service:**
   - Lese `OnCalendar` aus systemd-Timer
   - Parse Schedule-Typ (hourly/daily/weekly)
   - Berechne letzten Run **vor** Ziel-Zeitpunkt
   - Alter = target_epoch - last_run_epoch
   - Status = (age <= window) ? GREEN : YELLOW/RED

3. **Gesamt-Status:**
   - Alle GREEN â†’ GREEN
   - Mind. 1 YELLOW â†’ YELLOW
   - Mind. 1 RED â†’ RED

**OnCalendar-Parsing:**
```bash
# *-*-* *:20:00 â†’ hourly @ :20
# *-*-* 03:40:00 â†’ daily @ 03:40
# Sun 09:00 â†’ weekly Sunday @ 09:00
# Mon..Sat 09:00 â†’ daily Mon-Sat @ 09:00
```

**Last-Run-Berechnung:**
```bash
# Beispiel: hourly @ :20, Target = Mo 05:00
# â†’ LastRun = Mo 04:20 (40 Min vorher)

# Beispiel: daily @ 03:40, Target = Mo 05:00
# â†’ LastRun = Mo 03:40 (80 Min vorher)
```

### Use Cases

**Backup-Slot-Planung:**
```bash
# Ist Mo 05:00 sicher fÃ¼r RTB-Backup?
./forecast_safety_gate.sh 1

# Ergebnis GREEN â†’ Backup starten
```

**Timer-Overlap-Detektion:**
```bash
# Forecast fÃ¼r mehrere Zeitpunkte
for day in {1..7}; do
  ./forecast_safety_gate.sh $day | grep "FORECAST RESULT"
done
```

**Cronjob-Integration:**
```bash
# Warnung bei zukÃ¼nftigem RED
if ./forecast_safety_gate.sh 1 | grep -q "RED"; then
  echo "WARNING: Morgen Safety-Gate RED!"
  send_alert_mail
fi
```

### Troubleshooting

**Problem:** "Forecast zeigt falsches LastRun"

**Ursache:** OnCalendar-Parsing-Fehler oder Timezone-Drift.

**LÃ¶sung:**
```bash
# Timer-Schedule manuell prÃ¼fen
systemctl show entropywatcher-nas.timer | grep OnCalendar

# Manuellen Forecast mit Debug
FORECAST_DEBUG=1 ./forecast_safety_gate.sh 1
```

---

## ğŸ“¦ scripts/ew_backup_slot_check.sh

**Zweck:** PrÃ¼ft, ob EntropyWatcher-Services fÃ¼r geplante Backup-Slots (04:00, 12:00, 20:00) innerhalb ihrer Health-Windows liegen.

### Funktionsweise

1. **Backup-Tag ermitteln:** Aus `backup-pipeline.timer` oder via Argument
2. **FÃ¼r jeden Slot:** Simuliert letzten Scan-Zeitpunkt vor dem Slot
3. **Validierung:** PrÃ¼ft Alter vs. HEALTH_WINDOW_MIN
4. **Output:** Tabelle mit Service-Status pro Slot

### Usage

```bash
# NÃ¤chster geplanter Backup-Tag (aus backup-pipeline.timer)
./scripts/ew_backup_slot_check.sh

# Heute
./scripts/ew_backup_slot_check.sh 0

# Morgen
./scripts/ew_backup_slot_check.sh 1

# Ãœbermorgen
./scripts/ew_backup_slot_check.sh 2
```

### Output-Beispiel

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BACKUP SLOT CHECK: 2025-12-15 (Mo)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Slot: 04:00
Service  EffLastRun (@ 04:00)         Window   Status
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
nas      2025-12-15 03:20             75       OK
nas-av   2025-12-14 09:00             1560     OK

Slot: 12:00
Service  EffLastRun (@ 12:00)         Window   Status
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
nas      2025-12-15 11:20             75       OK
nas-av   2025-12-14 09:00             1560     OK

Slot: 20:00
Service  EffLastRun (@ 20:00)         Window   Status
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
nas      2025-12-15 19:20             75       OK
nas-av   2025-12-14 09:00             1560     OK
```

### Architektur

**Service-Konfiguration:**
```bash
# In /opt/apps/entropywatcher/config/
SERVICES=(
  "nas:60"       # stÃ¼ndlich (60 min)
  "nas-av:1440"  # tÃ¤glich (1440 min)
)
```

**Simulation-Logik:**
1. **VERGANGENHEIT:** Letzten echten Scan aus MySQL holen
2. **ZUKUNFT:** Letzten Lauf aus systemd-Timer + Frequenz vorwÃ¤rts springen

**DB-Zugriff:**
- BenÃ¶tigt MySQL-Credentials aus `common.env` + Service-ENV
- Query: `SELECT MAX(scan_timestamp) FROM scan_logs WHERE service='$svc' AND scan_timestamp < '$before_ts'`

### Environment Variables

```bash
# CONFIG_DIR (Default: /opt/apps/entropywatcher/config)
CONFIG_DIR=/custom/path ./scripts/ew_backup_slot_check.sh
```

### Use Cases

**Backup-Pipeline-Planung:**
```bash
# Vor Backup-Pipeline: PrÃ¼fen ob alle Slots OK
if ./scripts/ew_backup_slot_check.sh | grep -q "OLD"; then
  echo "WARNING: Mindestens ein Slot hat veraltete Scans"
  send_alert
fi
```

**Proaktive Warnungen:**
```bash
# Cronjob: TÃ¤glich um 18:00 fÃ¼r morgigen Backup-Tag
0 18 * * * /opt/apps/entropywatcher/scripts/ew_backup_slot_check.sh 1 | grep -q "OLD" && alert_admin
```

**Timer-Overlap-Detection:**
```bash
# PrÃ¼fen ob Timer-Frequenz fÃ¼r Slots ausreicht
./scripts/ew_backup_slot_check.sh 0
```

### Troubleshooting

**Problem:** "PARSE-ERROR" oder "DATE-ERROR"

**Ursache:** systemd-Timer-Output konnte nicht geparst werden.

**LÃ¶sung:**
```bash
# Timer-Status prÃ¼fen
systemctl list-timers entropywatcher-nas.timer

# Manueller Parse-Test
systemctl list-timers entropywatcher-nas.timer | awk 'NR==2 {print $5, $6}'
```

**Problem:** "TIMER-DISABLED"

**Ursache:** Service-Timer ist nicht enabled/active.

**LÃ¶sung:**
```bash
# Timer enablen + starten
sudo systemctl enable entropywatcher-nas.timer
sudo systemctl start entropywatcher-nas.timer
```

**Problem:** DB-Zugriff schlÃ¤gt fehl

**Ursache:** MySQL-Credentials fehlen oder falsch.

**LÃ¶sung:**
```bash
# Credentials prÃ¼fen
grep -E '^DB_' /opt/apps/entropywatcher/config/common.env

# MySQL-Verbindung testen
mysql -h"$DB_HOST" -u"$DB_USER" -p"$DB_PASS" "$DB_NAME" -e "SELECT 1"
```

---

## ğŸ”’ honeyfile_monitor.sh

**Zweck:** Ãœberwacht Honeyfile-Zugriffe via auditd und sendet Alert-Mails bei unbefugten Zugriffen.

**Hinweis:** Wird typischerweise als systemd-Service im Hintergrund ausgefÃ¼hrt, nicht manuell.

### Funktionsweise

1. **Audit-Log Ã¼berwachen:** PrÃ¼ft alle 60 Sekunden auf neue Honeyfile-Zugriffe (audit-key: `honeyfile_access`)
2. **Alert-Flag setzen:** Schreibt `/var/lib/honeyfile_alert` (blockiert Safety-Gate)
3. **Mail-Versand:** Sendet Alarm-Mail mit Details (Zeitpunkt, User, Pfad, Prozess)
4. **Logging:** Schreibt Ereignisse nach `/var/log/honeyfile_monitor.log`

### Usage

```bash
# Manueller Start (fÃ¼r Testing)
sudo ./honeyfile_monitor.sh

# Als systemd-Service (Production)
sudo systemctl start honeyfile-monitor.service
sudo systemctl enable honeyfile-monitor.service
```

### Architektur

**Config-Files:**
- `/opt/apps/entropywatcher/config/honeyfile_paths` - Liste aller Honeyfile-Pfade
- `/opt/apps/entropywatcher/config/common.env` - SMTP-Credentials fÃ¼r Mail-Versand

**State-Files:**
- `/var/lib/honeyfile_alert` - Flag-File (Safety-Gate prÃ¼ft dieses)
- `/var/lib/honeyfile_last_alert_ts` - Timestamp des letzten Alerts (verhindert Spam)

**Audit-Log:**
```bash
# Manuelle PrÃ¼fung
sudo ausearch -k honeyfile_access --start recent

# Output-Format:
# type=SYSCALL ... exe="/usr/bin/cat" ... key="honeyfile_access"
```

### Environment Variables

```bash
# Alle in common.env:
MAIL_FROM="alert@example.com"
MAIL_TO="admin@example.com"
MAIL_SMTP_HOST="smtp.example.com"
MAIL_SMTP_PORT=587
MAIL_SMTP_USER="user"
MAIL_SMTP_PASS="password"
MAIL_SMTP_TLS=true

# Optional:
HONEYFILE_LOG_FILE=/custom/path/honeyfile.log
COMMON_ENV=/custom/path/common.env
```

### Integration

**systemd-Service:**
```ini
# /etc/systemd/system/honeyfile-monitor.service
[Unit]
Description=Honeyfile Access Monitor
After=auditd.service

[Service]
Type=simple
User=root
ExecStart=/opt/apps/entropywatcher/honeyfile_monitor.sh
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

**Safety-Gate-Check:**
```bash
# In safety_gate.sh:
if [[ -f /var/lib/honeyfile_alert ]]; then
  echo "âŒ SYSTEM KOMPROMITTIERT - Honeyfile-Zugriff detektiert!"
  exit 2  # RED
fi
```

### Troubleshooting

**Problem:** "Config nicht gefunden: /opt/apps/entropywatcher/config/honeyfile_paths"

**Ursache:** Honeyfile-Pfade nicht konfiguriert.

**LÃ¶sung:**
```bash
# setup_honeyfiles.sh ausfÃ¼hren (erstellt Config automatisch)
sudo /opt/apps/entropywatcher/tools/setup_honeyfiles.sh
```

**Problem:** Mail-Versand schlÃ¤gt fehl

**Ursache:** SMTP-Credentials in `common.env` fehlen oder falsch.

**LÃ¶sung:**
```bash
# SMTP-Credentials prÃ¼fen
grep -E '^MAIL_' /opt/apps/entropywatcher/config/common.env

# Manueller Mail-Test (mit Python)
python3 -c "import smtplib; smtplib.SMTP('$MAIL_SMTP_HOST', $MAIL_SMTP_PORT).quit()"
```

**Problem:** Audit-Log zeigt keine Events

**Ursache:** auditd-Regeln nicht geladen.

**LÃ¶sung:**
```bash
# Audit-Regeln prÃ¼fen
sudo auditctl -l | grep honeyfile

# Falls leer: setup_honeyfiles.sh erneut ausfÃ¼hren
sudo /opt/apps/entropywatcher/tools/setup_honeyfiles.sh
```

**Problem:** Alert-Flag bleibt nach Check bestehen

**Ursache:** Alert-Flag muss **manuell** entfernt werden (nach Incident-Response).

**LÃ¶sung:**
```bash
# OnCalendar manuell prÃ¼fen
systemctl cat entropywatcher-nas.timer | grep OnCalendar

# Timezone prÃ¼fen
timedatectl status
```

**Problem:** "Status immer RED"

**Ursache:** `HEALTH_WINDOW_MIN` zu eng fÃ¼r Forecast-Zeitpunkt.

**LÃ¶sung:**
```bash
# Window erweitern (in service.env):
HEALTH_WINDOW_MIN=1560  # 26 Stunden fÃ¼r tÃ¤gliche Scans
```

---

## ğŸ”„ Zusammenspiel der Scripts

**Typischer Backup-Workflow:**

```bash
# 1. Pre-Backup: Safety-Gate prÃ¼fen (honeyfile_monitor.sh hat Flag gesetzt?)
if ! /opt/apps/entropywatcher/main/safety_gate.sh; then
  echo "Backup blockiert - Safety-Gate nicht GREEN"
  exit 1
fi

# 2. Backup durchfÃ¼hren (RTB/pCloud)
rsync_time_backup ...

# 3. Status-Dashboard anzeigen (nach Backup)
./scripts/ew_status.sh /opt/apps/entropywatcher/config dashboard

# 4. Forecast fÃ¼r morgen (Planung)
./scripts/forecast_safety_gate.sh 1

# 5. Backup-Slots fÃ¼r morgen prÃ¼fen
./scripts/ew_backup_slot_check.sh 1
```

**Monitoring-Integration:**

```bash
# Cronjob: TÃ¤glich um 06:00 Status-Mail
0 6 * * * /opt/apps/entropywatcher/main/scripts/ew_status.sh /opt/apps/entropywatcher/config mail

# Cronjob: StÃ¼ndlich Timer-Check
0 * * * * /opt/apps/entropywatcher/main/scripts/ew_forecast_next_run.sh | grep -qE "(active|enabled)" || alert_admin

# Cronjob: Vor Backup-Slot (04:50) Forecast prÃ¼fen
50 4 * * * /opt/apps/entropywatcher/main/scripts/forecast_safety_gate.sh 0 | grep -q "GREEN" || skip_backup

# Cronjob: TÃ¤glich um 18:00 Backup-Slots fÃ¼r morgen prÃ¼fen
0 18 * * * /opt/apps/entropywatcher/main/scripts/ew_backup_slot_check.sh 1 | grep -q "OLD" && alert_admin
```

**Hinweis zu Python-venv:**

Einige Scripts (besonders `scripts/ew_status.sh` und `scripts/ew_backup_slot_check.sh`) benÃ¶tigen DB-Zugriff und damit die **Python-venv**:

```bash
# Manueller Aufruf mit venv-Aktivierung:
cd /opt/apps/entropywatcher/main
source ../venv/bin/activate
./scripts/ew_status.sh ../config dashboard

# Oder direkt mit venv-Python:
/opt/apps/entropywatcher/venv/bin/python entropywatcher.py --env /opt/apps/entropywatcher/config/common.env --env /opt/apps/entropywatcher/config/nas.env status
```

**FÃ¼r Cronjobs:**
```bash
# Option 1: venv in Cronjob aktivieren
0 6 * * * cd /opt/apps/entropywatcher/main && source ../venv/bin/activate && ./scripts/ew_status.sh ../config mail

# Option 2: Wrapper-Script mit venv-Aktivierung
0 6 * * * /opt/apps/entropywatcher/main/run_with_venv.sh ./scripts/ew_status.sh ../config mail
```

# Cronjob: StÃ¼ndlich Timer-Check
0 * * * * /opt/apps/entropywatcher/scripts/ew_forecast_next_run.sh | grep -qE "(active|enabled)" || alert_admin

# Cronjob: Vor Backup-Slot (04:50) Forecast prÃ¼fen
50 4 * * * /opt/apps/entropywatcher/scripts/forecast_safety_gate.sh 0 | grep -q "GREEN" || skip_backup
```

---

## ğŸ“š Siehe auch

- **[README.md](../README.md)** - Hauptdokumentation
- **[docs/CONFIG.md](CONFIG.md)** - ENV-Variablen-Referenz
- **[docs/HONEYFILE_SETUP.md](HONEYFILE_SETUP.md)** - Intrusion Detection
- **[tools/README.md](../tools/README.md)** - Helper-Scripts

---

## ğŸ› ï¸ Entwickler-Notizen

### Performance

**ew_status.sh:**
- MySQL-Queries: ~100ms pro Service
- HTML-Generierung: ~50ms
- Gesamt: < 1 Sekunde fÃ¼r 6 Services

**forecast_safety_gate.sh:**
- systemctl-Aufrufe: ~200ms pro Service
- OnCalendar-Parsing: ~10ms
- Gesamt: < 2 Sekunden fÃ¼r 6 Services

### Erweiterungen

**Neue Checks in safety_gate.sh:**
```bash
# Beispiel: Disk-Space-Check hinzufÃ¼gen
check_disk_space() {
  local available=$(df /srv/nas | awk 'NR==2 {print $4}')
  if [[ $available -lt 10485760 ]]; then  # < 10 GB
    log "âœ— CRITICAL: Disk space < 10 GB"
    return 1
  fi
  return 0
}
```

**Neue Service-Types in forecast_safety_gate.sh:**
```bash
# Beispiel: Monatliche Scans unterstÃ¼tzen
parse_schedule() {
  # ... existing patterns ...
  
  # *-*-01 HH:MM â†’ monthly
  elif [[ "$oncalendar" =~ ^\*-\*-01[[:space:]]+ ]]; then
    echo "monthly:2592000"
  fi
}
```
